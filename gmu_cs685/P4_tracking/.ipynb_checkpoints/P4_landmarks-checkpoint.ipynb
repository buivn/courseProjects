{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0259df54",
   "metadata": {},
   "source": [
    "# P4: Landmarks, Data Association, and SLAM\n",
    "\n",
    "Instructions the same as they have been. You may need to install a few more packages:\n",
    "\n",
    "```\n",
    "pip3 install scipy opencv-python gtsam\n",
    "```\n",
    "\n",
    "## P4.1 Triangulation \n",
    "\n",
    "In class, we discussed how you could extract information about a 3D scene given two cameras and their camera projection matrices. Here, we will investigate a simple example to learn the fundamentals.\n",
    "\n",
    "### P4.1.1 Projecting Into Image Space\n",
    "\n",
    "Below, I have provided you with two images taken by two cameras `a` and `b`. In this question, we will go over some camera basics, namely how to compute the image-space point from a 3D point in the scene and the known camera matrices.\n",
    "\n",
    "Some information about the two camera matrices:\n",
    "- The first camera is translated such that `t_a = [0, -0.2, 5]` and `t_b = [-1.5, 0, 5]`\n",
    "- No rotation is applied to either camera (so the rotation matrix is the identity matrix)\n",
    "- The focal length of the camera (for these 1024 px) images is `f = 1170.3` (in units of pixels).\n",
    "- The camera center is located at the center of the image.\n",
    "\n",
    "**QUESTION** What are the camera matrices $P_a$ and $P_b$? I will accept either the final matrix, or the matrix written in terms of its component matrices (the intrinsic and extrinsic matrices), as long as these are explicitly defined.\n",
    "\n",
    "I have provided you with a single point below in 3D space `X0` that exists on one of the corners of the cube shown in the scene.\n",
    "\n",
    "**TASK + PLOTS** Implement the function `get_projected_point(P, X)` which takes in a camera matrix `P` and a 3D scene point `X`. If your matrices are implemented correctly, you should see that the projected 3D point overlaps with one of the corners of the cube in image space. Include the two images with the point `X0` projected onto the two images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fec351e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Starter code\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "def load_image(filepath):\n",
    "    \"\"\"Loads an image into a numpy array.\n",
    "    Note: image will have 3 color channels [r, g, b].\"\"\"\n",
    "    img = Image.open(filepath)\n",
    "    img = np.asarray(img).astype(float)/255\n",
    "    return img[:, :, :3]\n",
    "\n",
    "image_a = load_image('two_view_cube_image_a.png')\n",
    "image_b = load_image('two_view_cube_image_b.png')\n",
    "plt.figure()\n",
    "plt.subplot(121)\n",
    "plt.imshow(image_a)\n",
    "plt.subplot(122)\n",
    "plt.imshow(image_b)\n",
    "\n",
    "None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "025cf374",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TASK: Implement the camera matrices & get_projected_point\n",
    "f = 1137.8\n",
    "Pa = None\n",
    "Pb = None\n",
    "\n",
    "X0 = np.array([ 0.85244616, 0.9508618, -0.51819406])\n",
    "points_3D = [X0]\n",
    "\n",
    "def get_projected_point(P, X):\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0057321",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Plotting Code\n",
    "if Pa is None or Pb is None:\n",
    "    raise NotImplementedError(\"Define the camera matrices.\")\n",
    "\n",
    "def visualize_projected_points(image, P, points_3D, verbose=False):\n",
    "    plt.figure(dpi=100)\n",
    "    plt.imshow(image)\n",
    "    for X in points_3D:\n",
    "        x = get_projected_point(P, X)\n",
    "        if verbose:\n",
    "            print(x)\n",
    "        plt.plot(x[0], x[1], 'ko')\n",
    "\n",
    "visualize_projected_points(image_a, Pa, points_3D)\n",
    "visualize_projected_points(image_b, Pb, points_3D)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f85c4e5c",
   "metadata": {},
   "source": [
    "### P4.1.2 Determining the Size of the Cube\n",
    "\n",
    "Now you will invert this operation. In class, we discussed how to triangulate a point from two correspondences. The relevant slide from L15 (two-view modeling) is as follows:\n",
    "\n",
    "<img src=\"triangulation_lin_alg.png\" width=\"400\">\n",
    "\n",
    "(*Note*: I have used `Pa` and `Pb` to denote the image matrices, whereas the included slide uses $p$ and $p'$.) You can use SVD to solve for the \"best\" value of the 3D point $X$ (equivalently, you can find the minimum eigenvector of $A^T A$). Manually determine the (x, y) coordinates of two corners in the provided images (from the upper left corner) and use them as part of this triangulation procedure. By finding the 3D point corresponding to two of the corners and computing the distance between them, you should be able to compute the size of the cube in the images.\n",
    "\n",
    "**TASK** Pick two corners of the cube and include the $(x, y)$ image coordinates for both `image_a` and `image_b` and the 3D world coordinate $(X, Y, Z)$ in your writeup.\n",
    "\n",
    "**QUESTION** What is the side length of the cube shown in the two images above? (The answer might be somewhat sensitive to the coordinates you measure in image space, though we are only looking for a \"close enough\" number within maybe 10%â€“20% of the \"correct\" answer. You should feel free to use more than two points and average the results to get a more accurate result.)\n",
    "\n",
    "You can confirm that your estimated 3D coordinates are correct by reprojecting them back into image space using your solution from the previous question to check for accuracy.\n",
    "\n",
    "> **We will use your full response to evaluate partial credit, so be sure to enumerate the steps you took and (if you feel it helpful) intermediate results or code snippets.**\n",
    "\n",
    "### P4.1.3 Incorporating Noise (Pt. 1)\n",
    "\n",
    "While you can identify roughly where the point is located, it's unlikely that you will pick the corner point exactly. Your measurements are *noisy*. What if we were to incorporate uncertianty into our measurements? \n",
    "\n",
    "For this question, assume that your measurements have a Gaussian noise with a standard deviation of 5 pixels. It is the goal of this question to compute the mean and covariance of the for points in 3D space.\n",
    "\n",
    "**QUESTION** (3-8 sentences) Describe a procedure for how you would compute the mean and covariance of the 3D position of the corner of the cube given the noise model defined above. Note: there might not be an analytic formula for these, so an algorithmic and/or approximate solution is acceptable. You may find the documentation for `numpy.cov` to be helpful: https://numpy.org/doc/stable/reference/generated/numpy.cov.html\n",
    "\n",
    "**TASK** Implement your procedure.\n",
    "\n",
    "**CODE** Include your code in your writeup.\n",
    "\n",
    "**ANSWER** Include your result (the mean and 3D covariance matrix) for two of the points.\n",
    "\n",
    "**QUESTION** (2-4 sentences) Why might the mean of this result differn from the value you computed in the previous question?\n",
    "\n",
    "### P4.1.4 Incorporating Noise (Pt. 2)\n",
    "\n",
    "Let's next consider how this uncertainty impacts our estimate of the size of the cube.\n",
    "\n",
    "**QUESTION** (3-8 sentences) Describe a procedure for how you would compute the mean and variance of the length of a side of the cube from observations of two of the corners and the noise model from above.\n",
    "\n",
    "**TASK** Implement your procedure.\n",
    "\n",
    "**CODE** Include your code in your writeup.\n",
    "\n",
    "**ANSWER** Include your result in your writeup: the mean and (1D) variance for the length of the cube."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06db7f5b",
   "metadata": {},
   "source": [
    "## P4.2 Simple Simultaneous Localization and Mapping\n",
    "\n",
    "Now, we're going to start putting some concepts together and use `gtsam` to both localize the robot and simultaneously track landmarks spread throughout the environment.\n",
    "\n",
    "I have given you some code below that generates observations from points in the environment. Each observation is a series of detections of nearby landmarks (just points in space for this example): each detection is a 3-element vector of the relative x and y coordinates and the ID of the detected landmark; we assume for now that in addition to the (noisy) relative position of the landmark, we also know which landmark it is, an assumption we will relax in the next part of the assignment.\n",
    "\n",
    "Run the code below to see what these noisy observations look (blue) like compared to the true landmarks (pale magenta):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "999c14f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from common import Pose\n",
    "\n",
    "np.random.seed(1234)\n",
    "\n",
    "num_landmarks = 80\n",
    "landmarks = np.array(list(zip(\n",
    "    100 * np.random.rand(num_landmarks) - 20,\n",
    "    100 * np.random.rand(num_landmarks) - 20,\n",
    "    np.arange(num_landmarks))))\n",
    "\n",
    "def get_observation(pose, range_limit=15, noise_sigma=0.5):\n",
    "    distances = np.linalg.norm(landmarks[:,:2] - np.array([pose.x, pose.y]), axis=1)\n",
    "    ego_landmarks = landmarks[distances < range_limit] - np.array([pose.x, pose.y, 0])\n",
    "    ego_landmarks[:, :2] += noise_sigma * np.random.normal(size=ego_landmarks[:, :2].shape)\n",
    "    return ego_landmarks\n",
    "\n",
    "def plot_observation(pose, observation):\n",
    "    plt.plot([pose.x], [pose.y], 'gx')\n",
    "    plt.plot(pose.x + observation[:, 0], \n",
    "             pose.y + observation[:, 1], '.')\n",
    "\n",
    "pose = Pose(20, 50, 0)\n",
    "observation = get_observation(pose)\n",
    "print(\"relative x,     relative y,  id#\")\n",
    "print(observation)\n",
    "plt.plot(landmarks[:, 0], landmarks[:, 1], 'mo', alpha=0.2)\n",
    "plot_observation(pose, observation)\n",
    "None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10df1649",
   "metadata": {},
   "source": [
    "I have provided you with a function `get_noisy_motion` that simulates the robot moving throughout the environment and, at each time step, collecting noisy observations of the nearby landmarks. The robot does not have any GPS measurements! Instead, we'll rely on the detected landmarks to help us keep track of where we are.\n",
    "\n",
    "I have given you some starter code below. Your task will be to finish the GTSAM implementation and use it to localize both the robot and the landmarks.\n",
    "\n",
    "Also, keeping track of all the indices and such between the poses and landmarks can be a hastle, so instead you might consider using the GTSAM `symbol` classes: `X` and `L`, so that you can use `X(2)` to say \"pose 2\" and `L(5)` for the 5th landmark rather than needing a unique ID for everything (see my starter code below).\n",
    "\n",
    "## P4.2.1 Motion Only\n",
    "\n",
    "**TASK** Run the \"starter visualization code for landmark SLAM\" below so that you can see how the observations look without any SLAM.\n",
    "\n",
    "Motion of the robot, you should already be familiar with: it matches the question from P3, and relies on `BetweenFactorPoint2` factors to track the robot motion.\n",
    "\n",
    "**TASK** Add the robot poses and motion to GTSAM (no landmarks). Feel free to use your code from P3 to help you here. \n",
    "\n",
    "**PLOT** Plot the resulting motion (with uncertainty elipses) using the plotting code below and include in your writeup. You should see that the motion of the robot draws out roughly a square and that the uncertainty grows as the robot moves counterclockwise around the space.\n",
    "\n",
    "## P4.2.2 Adding Landmarks\n",
    "\n",
    "**QUESTION** [1-2 sentences] What type of factors relate the landmarks and the poses?\n",
    "\n",
    "**QUESTION** [2-3 sentences] Are there factors (edges in the graph) between landmarks? If so, what are they? If not, explain why.\n",
    "\n",
    "**TASK** Using GTSAM, implement landmark SLAM. Add the landmarks and their factors to the graph. Note: you need an initial estimate of the position of the landmarks. Coming up with that can be a bit tricky and, while possible to get a better initial estimate, I suggest you just use [50, 50] for all the landmarks; the optimizer should be able to figure out where everything belongs.\n",
    "\n",
    "**PLOT** Include the plot showing your result (it should have both the robot poses and the landmarks).\n",
    "\n",
    "**QUESTION** [3-5 seconds] You may notice that the uncertainty over the positions of some of the landmarks is greater or less than the others. Explain why this may be. Feel free to point to specific examples from your plots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "286f24f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Starter visualization code for landmark SLAM\n",
    "import gtsam\n",
    "import gtsam.utils.plot as gtsam_plot\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from matplotlib import patches\n",
    "\n",
    "def plot_point2_on_axes(axes, point, P=None, color=None):\n",
    "    if color is not None:\n",
    "        axes.plot([point[0]], [point[1]], marker='.', color=color, markersize=8)\n",
    "    else:\n",
    "        axes.plot([point[0]], [point[1]], marker='.', markersize=8)\n",
    "    if P is not None:\n",
    "        w, v = np.linalg.eigh(P)\n",
    "        # this corresponds to 95%\n",
    "        k = 2.447746830681\n",
    "\n",
    "        angle = np.arctan2(v[1, 0], v[0, 0])\n",
    "        e1 = patches.Ellipse(point,\n",
    "                             np.sqrt(w[0]) * 2 * k,\n",
    "                             np.sqrt(w[1]) * 2 * k,\n",
    "                             np.rad2deg(angle),\n",
    "                             fill=False,\n",
    "                             alpha=0.3)\n",
    "        axes.add_patch(e1)\n",
    "\n",
    "\n",
    "def print_result_point2(result):\n",
    "    for key in result.keys():\n",
    "        print(f\"Point[{key}]:\\n\"\n",
    "              f\"  Location: {result.atPoint2(key)}, \\n\"\n",
    "              f\"  Covariance: \\n{marginals.marginalCovariance(key)}\\n\" )\n",
    "\n",
    "def plot_result_point2(result):\n",
    "    ax = plt.gca()\n",
    "    for key in result.keys():\n",
    "        plot_point2_on_axes(\n",
    "            ax, result.atPoint2(key), marginals.marginalCovariance(key))\n",
    "    \n",
    "    plt.axis('equal')\n",
    "    plt.show()\n",
    "    \n",
    "def get_noisy_motion(do_plot=False):\n",
    "    np.random.seed(1234)\n",
    "    steps = 100\n",
    "    std = 0.2\n",
    "\n",
    "    # Robot moving generally rightward\n",
    "    dx_true = np.concatenate(\n",
    "        [np.random.normal(2.5, 0.2, size=[steps//4]),\n",
    "         np.random.normal(0.0, 0.2, size=[steps//4]),\n",
    "         np.random.normal(-2.5, 0.2, size=[steps//4]),\n",
    "         np.random.normal(0.0, 0.2, size=[steps//4])],\n",
    "        axis=0)\n",
    "    dy_true = np.concatenate(\n",
    "        [np.random.normal(0.0, 0.2, size=[steps//4]),\n",
    "         np.random.normal(2.5, 0.2, size=[steps//4]),\n",
    "         np.random.normal(0.0, 0.2, size=[steps//4]),\n",
    "         np.random.normal(-2.5, 0.2, size=[steps//4])],\n",
    "        axis=0)\n",
    "\n",
    "    dx_noisy = dx_true + np.random.normal(0.0, 0.3, size=[steps])\n",
    "    dy_noisy = dy_true + np.random.normal(0.0, 0.3, size=[steps])\n",
    "\n",
    "    x_true = np.cumsum(np.concatenate(([0], dx_true), axis=0))\n",
    "    y_true = np.cumsum(np.concatenate(([0], dy_true), axis=0))\n",
    "\n",
    "    observations = [get_observation(Pose(xt, yt, 0))\n",
    "                    for xt, yt in zip(np.cumsum(dx_true), np.cumsum(dy_true))]\n",
    "\n",
    "    return x_true, y_true, dx_noisy, dy_noisy, observations\n",
    "\n",
    "x_true, y_true, dx_noisy, dy_noisy, observations = get_noisy_motion(do_plot=True)\n",
    "\n",
    "# Plot the noisy data\n",
    "x_noisy = np.cumsum(np.concatenate(([0], dx_noisy), axis=0))\n",
    "y_noisy = np.cumsum(np.concatenate(([0], dy_noisy), axis=0))\n",
    "plt.plot(x_true, y_true, ':m', alpha=0.3)\n",
    "plt.plot(landmarks[:, 0], landmarks[:, 1], 'mo', alpha=0.2)\n",
    "for ii, (xn, yn, observation) in enumerate(zip(x_noisy[1:], y_noisy[1:], observations)):\n",
    "    plot_observation(Pose(xn, yn), observation)\n",
    "\n",
    "None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f33bed0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gtsam import symbol_shorthand\n",
    "L = symbol_shorthand.L\n",
    "X = symbol_shorthand.X\n",
    "\n",
    "# Create noise models\n",
    "PRIOR_NOISE = gtsam.noiseModel.Diagonal.Sigmas(np.array([0.1, 0.1], dtype=float))\n",
    "ODOMETRY_NOISE = gtsam.noiseModel.Diagonal.Sigmas(np.array([0.3, 0.3], dtype=float))\n",
    "LANDMARK_NOISE = gtsam.noiseModel.Diagonal.Sigmas(np.array([0.5, 0.5], dtype=float))\n",
    "\n",
    "x_true, y_true, dx_noisy, dy_noisy, observations = get_noisy_motion(do_plot=False)\n",
    "\n",
    "graph = gtsam.NonlinearFactorGraph()\n",
    "initial_estimate = gtsam.Values()\n",
    "\n",
    "graph.add(gtsam.PriorFactorPoint2(X(0), gtsam.Point2(0, 0), PRIOR_NOISE))\n",
    "\n",
    "# Now you do the rest!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beceabf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters for the optimization\n",
    "parameters = gtsam.GaussNewtonParams()\n",
    "parameters.setRelativeErrorTol(1e-5)\n",
    "parameters.setMaxIterations(1000)\n",
    "optimizer = gtsam.GaussNewtonOptimizer(graph, initial_estimate, parameters)\n",
    "result = optimizer.optimize()\n",
    "marginals = gtsam.Marginals(graph, result)\n",
    "\n",
    "# Printing and Plotting\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.plot(x_true, y_true, ':m', alpha=0.3)\n",
    "plt.plot(landmarks[:, 0], landmarks[:, 1], 'mo', alpha=0.2)\n",
    "# print_result_point2(result)\n",
    "plot_result_point2(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b8250cc",
   "metadata": {},
   "source": [
    "### P4.3 Data Association\n",
    "\n",
    "In the last question, we assumed that we knew which detection corresponded to which landmark. Now, we're going to relax that assumption.\n",
    "\n",
    "### P4.3.1 Naive (Gaussian) Data Association\n",
    "\n",
    "Here I have provided you with some code that performs very simple data associations: for each detection (in each observation) we compute the likelihood of that point being an observation of an existing landmark. If that probability is within some threshold, it is added as a detection of that landmark, otherwise a new landmark is created.\n",
    "\n",
    "**TASK** Run the code below and observe the result. You should also seek to understand the code; it will serve as your starting point for the next question. [You do not need to include any plots in your writeup for this question, since I am giving you working code.]\n",
    "\n",
    "**QUESTION** (2-4 sentences) You may notice that a few of the landmarks (magenta circles) have two observed landmarks (black dots) near them. Explain why this occurs.\n",
    "\n",
    "**QUESTION** (3-5 sentences) Increase the association threshold from 4 to 16 and observe what happens for the case with perfect positions (the left plot).  Explain what happens and why."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "744dfdd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data association: initial implementation\n",
    "\n",
    "class Landmark(object):\n",
    "    def __init__(self, obs, pose, pose_id):\n",
    "        # self.position = detection\n",
    "        self.detections = []\n",
    "        self.add_detection(obs, pose, pose_id)\n",
    "        self.update_position()\n",
    "    \n",
    "    def add_detection(self, obs, pose, pose_id):\n",
    "        self.detections.append((obs, pose, pose_id))\n",
    "        \n",
    "    def update_position(self):\n",
    "        self.position = np.mean(\n",
    "            [obs[:2] + [pose.x, pose.y] for obs, pose, _ in self.detections],\n",
    "            axis=0\n",
    "        )\n",
    "\n",
    "    def prob_of_obs(self, obs, pose, sigma=0.5):\n",
    "        return np.exp(- ((self.position[0] - pose.x - obs[0])**2 \n",
    "                         + (self.position[1] - pose.y - obs[1])**2) \n",
    "                     / (2 * sigma * sigma))\n",
    "\n",
    "\n",
    "def update_landmarks(landmark_set, observation, pose, pose_id, association_thresh=4):\n",
    "    # Use a simple approach\n",
    "    for obs in observation:\n",
    "        probs = [l.prob_of_obs(obs, pose) for l in landmark_set]\n",
    "        \n",
    "        if not len(landmark_set) or max(probs) < np.exp(-association_thresh**2/2):\n",
    "            landmark_set.append(Landmark(obs, pose, pose_id))\n",
    "        else:\n",
    "            landmark_set[np.argmax(probs)].add_detection(obs, pose, pose_id)\n",
    "    for landmark in landmark_set:\n",
    "        landmark.update_position()\n",
    "        \n",
    "# With the true positions\n",
    "plt.figure(figsize=(10, 5))\n",
    "\n",
    "x_true, y_true, dx_noisy, dy_noisy, observations = get_noisy_motion(do_plot=True)\n",
    "\n",
    "plt.subplot(121)\n",
    "detected_landmarks = []\n",
    "for ii, (xt, yt, observation) in enumerate(zip(x_true[1:], y_true[1:], observations)):\n",
    "    update_landmarks(detected_landmarks, observation, Pose(xt, yt), ii+1)\n",
    "\n",
    "plt.plot(x_true, y_true, ':m', alpha=0.3)\n",
    "plt.plot(landmarks[:, 0], landmarks[:, 1], 'mo', alpha=0.2)\n",
    "for l in detected_landmarks:\n",
    "    plt.plot([l.position[0]], [l.position[1]], 'k.')\n",
    "plt.axis('equal')\n",
    "\n",
    "\n",
    "# With noisy positions\n",
    "plt.subplot(122)\n",
    "x_noisy = np.cumsum(np.concatenate(([0], dx_noisy), axis=0))\n",
    "y_noisy = np.cumsum(np.concatenate(([0], dy_noisy), axis=0))\n",
    "detected_landmarks = []\n",
    "for ii, (xn, yn, observation) in enumerate(zip(x_noisy[1:], y_noisy[1:], observations)):\n",
    "    update_landmarks(detected_landmarks, observation, Pose(xn, yn), ii+1)\n",
    "\n",
    "plt.plot(x_true, y_true, ':m', alpha=0.3)\n",
    "plt.plot(x_noisy, y_noisy, ':k', alpha=0.8)\n",
    "plt.plot(landmarks[:, 0], landmarks[:, 1], 'mo', alpha=0.2)\n",
    "for l in detected_landmarks:\n",
    "    plt.plot([l.position[0]], [l.position[1]], 'k.')\n",
    "plt.axis('equal')\n",
    "\n",
    "None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3d56d0a",
   "metadata": {},
   "source": [
    "### 4.3.2 Linear Sum Assignment\n",
    "\n",
    "Unfortunately, matching using the function above has a limitation: it can associate multiple detections *per observation* to the same landmark if two landmarks are close together. This can be an issue if the landmarks tend to be \"clumped\". If you run the code below, you'll see exactly this behavior.\n",
    "\n",
    "Instead, we hope to maximize the likelhood of an observation while ensuring that no two detections in a single observation are associated with the same landmark. We can do that using *Linear Sum Assignment* (also often known as the \"Hungarian Matching Algorithm\"). Here, you will use the scipy implementation of the LSA algorithm to perform data association.\n",
    "\n",
    "To use the LSA algorithm, we need to define a cost matrix. We are hoping to maximize the likelhiood of a single observation, which is equivalent to minimizing the negative log likelihood of that observation. The benefit of using a logarithm is that while liklihoods multiply, log-likehoods add, allowing us to use linear sum assignment. Each entry in the cost matrix will be the negative log likelihood (as computed by `l.prob_of_obs`) for associating a particular detection with a particular landmark.\n",
    "\n",
    "The matrix should have a number of rows equal to the number of number of observations. The number of columns is more tricky since you need to allow the landmark to either match to an existing landmark if the likelihood is high enough or to create a new landmark if none of the existing ones is likely. The LSA algorithm does not support \"creation of new landmarks\", so we'll fake it instead: we add columns with fake landmarks and if the algorithm decides to associate with one of these we make a new landmark instead. This means that the number of columns will be the number of landmarks + the number of observations (since each observation could potentially be 'associated' with a new/fake landmark). While the values of the \"left\" block of the matrixâ€”corresponding to association with existing landmarksâ€”will have values defined by (though not necessarily equal to) `l.prob_of_obs`, the other elements for association with new landmarks will all have values defined by (though not equal to) the `association_thresh` above. Using this description of the cost matrix, you should be able to implement data association using linear sum assignment.\n",
    "\n",
    "**TASK** Implement the function `update_landmarks_lsa`, which has the same API as the `update_landmarks` function above. The function should rely on the `scipy.optimize.linear_sum_assignment` to associate detection to landmarks or decide whether a new landmark should be created. (You can `import scipy` for this.)\n",
    "\n",
    "**CODE** Include the implementation of `update_landmarks_lsa` (or a screenshot of it) in your writeup.\n",
    "\n",
    "**PLOTS** Include the results plots from the plotting code below in your writeup."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96756dd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Without ensuring exclusion\n",
    "plt.figure(figsize=(10, 5))\n",
    "\n",
    "x_true, y_true, dx_noisy, dy_noisy, observations = get_noisy_motion(do_plot=True)\n",
    "\n",
    "plt.subplot(121)\n",
    "detected_landmarks = []\n",
    "for ii, (xt, yt, observation) in enumerate(zip(x_true[1:], y_true[1:], observations)):\n",
    "    update_landmarks(detected_landmarks, observation, Pose(xt, yt), ii+1, association_thresh=16)\n",
    "\n",
    "plt.plot(x_true, y_true, ':m', alpha=0.3)\n",
    "plt.plot(landmarks[:, 0], landmarks[:, 1], 'mo', alpha=0.2)\n",
    "for l in detected_landmarks:\n",
    "    plt.plot([l.position[0]], [l.position[1]], 'k.')\n",
    "plt.axis('equal')\n",
    "\n",
    "\n",
    "# Using a matching algorithm to ensure exclusion\n",
    "plt.subplot(122)\n",
    "detected_landmarks = []\n",
    "for ii, (xt, yt, observation) in enumerate(zip(x_true[1:], y_true[1:], observations)):\n",
    "    update_landmarks_lsa(detected_landmarks, observation, Pose(xt, yt), ii+1, association_thresh=16)\n",
    "\n",
    "plt.plot(x_true, y_true, ':m', alpha=0.3)\n",
    "plt.plot(landmarks[:, 0], landmarks[:, 1], 'mo', alpha=0.2)\n",
    "for l in detected_landmarks:\n",
    "    plt.plot([l.position[0]], [l.position[1]], 'k.')\n",
    "plt.axis('equal')\n",
    "None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67aacc34",
   "metadata": {},
   "source": [
    "## P4.4 SLAM with Noisy Associations\n",
    "\n",
    "Now we're going to put everything together: SLAM with both odometry and observations of nearby landmarks yet without access to the ground truth data associations. I have provided you with a function `update_positions_gtsam` below that you will complete. The purpose of this function is to take in all the observations so far (including both motion and the landmark observations) and update the poositions of both the robot and the landmarks themselves. I recommend you read through the function to get an idea of how it is intended to work and what's expected of you to complete. Below that function, I have included some plotting code that uses both `update_positions_gtsam` and your data association code to incrementally build a map.\n",
    "\n",
    "> Note: to keep things simple, you rebuild the entire GTSAM graph each time you receive a new observation. In practice, the graph persists and is built incrementally.\n",
    "\n",
    "**TASK** Complete the `update_positions_gtsam` code. You should feel free to use your code from earlier, however you should *not rely on the true associations*. Instead, you should use the `Landmark` class that I have given you. Notice that for each landmark, a detection includes not only the position but also the `pose_ind`, the index of the pose at which that observation was collected. You will no doubt find this useful when constructing the `gtsam` graph.\n",
    "\n",
    "**CODE** Include your completed function (or a screenshot of it) in your writeup.\n",
    "\n",
    "**PLOT** Include the resulting plot from running the plotting code below in your writeup."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55278381",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Starter Code\n",
    "\n",
    "def update_positions_gtsam(dxs, dys, observations, landmarks):\n",
    "    from gtsam import symbol_shorthand\n",
    "    L = symbol_shorthand.L\n",
    "    X = symbol_shorthand.X\n",
    "\n",
    "    # Create noise models\n",
    "    PRIOR_NOISE = gtsam.noiseModel.Diagonal.Sigmas(np.array([0.1, 0.1], dtype=float))\n",
    "    ODOMETRY_NOISE = gtsam.noiseModel.Diagonal.Sigmas(np.array([0.3, 0.3], dtype=float))\n",
    "    LANDMARK_NOISE = gtsam.noiseModel.Diagonal.Sigmas(np.array([0.5, 0.5], dtype=float))\n",
    "\n",
    "    graph = gtsam.NonlinearFactorGraph()\n",
    "    initial_estimate = gtsam.Values()\n",
    "\n",
    "    graph.add(gtsam.PriorFactorPoint2(X(0), gtsam.Point2(0, 0), PRIOR_NOISE))\n",
    "\n",
    "    # Add the odometry factors\n",
    "    raise NotImplementedError()\n",
    "\n",
    "    # Set the initial estimates for the poses\n",
    "    x_noisy = np.cumsum(np.concatenate(([0], dxs), axis=0))\n",
    "    y_noisy = np.cumsum(np.concatenate(([0], dys), axis=0))\n",
    "    raise NotImplementedError()\n",
    "\n",
    "    # Add the observations for the landmarks\n",
    "    raise NotImplementedError()\n",
    "    \n",
    "    # Set the initial position of the landmarks\n",
    "    # Note: you can use the positions already stored in each landmark as an initial guess\n",
    "    raise NotImplementedError()\n",
    "\n",
    "    # Parameters for the optimization\n",
    "    parameters = gtsam.GaussNewtonParams()\n",
    "    parameters.setRelativeErrorTol(1e-5)\n",
    "    parameters.setMaxIterations(1000)\n",
    "    optimizer = gtsam.GaussNewtonOptimizer(graph, initial_estimate, parameters)\n",
    "    result = optimizer.optimize()\n",
    "    marginals = gtsam.Marginals(graph, result)\n",
    "    \n",
    "    # Get the values of the landmark positions.\n",
    "    # Note: you don't need to do it like this, but this is how I've done it.\n",
    "    # I recommend that you use the \"symbols\" L and X; it makes bookkeeping easier.\n",
    "    for lind, l in enumerate(landmarks):\n",
    "        l.position = result.atPoint2(L(lind))\n",
    "\n",
    "    return result.atPoint2(X(len(dxs))), result, marginals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d0217f9",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# plotting and results code\n",
    "\n",
    "x_true, y_true, dx_noisy, dy_noisy, observations = get_noisy_motion()\n",
    "detected_landmarks = []\n",
    "for tind in range(1, len(observations)):\n",
    "    # Use SLAM to update the robot and landmark positions\n",
    "    position, result, marginals = update_positions_gtsam(\n",
    "        dx_noisy[:tind+1], \n",
    "        dy_noisy[:tind+1], \n",
    "        observations[:tind],\n",
    "        detected_landmarks)\n",
    "\n",
    "    # Data association on the landmarks\n",
    "    update_landmarks_lsa(detected_landmarks, \n",
    "                         observations[tind][:, :2], \n",
    "                         Pose(position[0], position[1]), \n",
    "                         tind+1, \n",
    "                         association_thresh=8)\n",
    "\n",
    "    # Outputs\n",
    "    print(tind, len(detected_landmarks), position)\n",
    "\n",
    "# Printing and Plotting\n",
    "plt.figure(figsize=(6, 6))\n",
    "plt.plot(x_true, y_true, ':m', alpha=0.3)\n",
    "plt.plot(landmarks[:, 0], landmarks[:, 1], 'mo', alpha=0.2)\n",
    "plot_result_point2(result)\n",
    "None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a4adb02",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3 (CS685)",
   "language": "python",
   "name": "cs685venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
